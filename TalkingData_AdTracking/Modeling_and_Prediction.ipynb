{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import operator\n",
    "from glob import glob \n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lli2/Git/kaggle/TalkingData_AdTracking\n"
     ]
    }
   ],
   "source": [
    "cd \"/Users/lli2/Git/kaggle/TalkingData_AdTracking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycols = ['ip','app','device','os','channel','click_time','is_attributed']\n",
    "\n",
    "mytypes = {'ip':'uint32',\n",
    "           'app':'uint16',\n",
    "           'device':'uint16',\n",
    "           'os':'uint16',\n",
    "           'channel':'uint16',\n",
    "           'is_attributed':'uint16'}\n",
    "\n",
    "mydate = ['click_time']\n",
    "\n",
    "df_train = pd.read_csv('/Users/lli2/Git/kaggle_data/train.csv', \n",
    "                       nrows=10000000, usecols=mycols, dtype=mytypes, parse_dates=mydate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure non-null target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['is_attributed'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ip  app  device  os  channel          click_time  is_attributed\n",
       "0  83230    3       1  13      379 2017-11-06 14:32:21              0\n",
       "1  17357    3       1  19      379 2017-11-06 14:33:34              0\n",
       "2  35810    3       1  13      379 2017-11-06 14:34:12              0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip                       uint32\n",
       "app                      uint16\n",
       "device                   uint16\n",
       "os                       uint16\n",
       "channel                  uint16\n",
       "click_time       datetime64[ns]\n",
       "is_attributed            uint16\n",
       "dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: click_time, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_train.head(10)\n",
    "test['click_time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app', 'channel', 'click_time', 'device', 'ip', 'is_attributed', 'os'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_combinations(combo, data_lst, collector):\n",
    "    \n",
    "    for i in range(len(data_lst)):\n",
    "        \n",
    "        # deep cope for later update\n",
    "        new_combo = copy.copy(combo) \n",
    "        new_data_lst = copy.copy(data_lst)\n",
    "        \n",
    "        # populate combo & reduce rest candidates\n",
    "        new_combo.append(data_lst[i])\n",
    "        new_data_lst = data_lst[i+1:]\n",
    "        collector.append(new_combo)\n",
    "        \n",
    "        # go deeper by recursion\n",
    "        combinations(new_combo, new_data_lst, collector)\n",
    "        \n",
    "    return collector\n",
    "        \n",
    "\n",
    "\n",
    "def remove_flat_columns(df, cut_threshold=0.99999):\n",
    "    # If the top frequent value/NA counts for x% of the column, remove the column.\n",
    "    nrow = df.shape[0]\n",
    "    same_pct = dict(df.apply(lambda x: x.value_counts(dropna=False).max()/nrow, axis=0))\n",
    "    cols_to_remove = [k for k, v in same_pct.items() if v > cut_threshold]\n",
    "    \n",
    "    df = df.drop(cols_to_remove, axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "def clicks_creation(new_data, target_var):\n",
    "    \n",
    "    if target_var not in new_data.columns:\n",
    "        print(\"Error: The given target variable does not exist!\")\n",
    "        return None, None\n",
    "    \n",
    "    else:\n",
    "        # click_time\n",
    "        new_data['clk_date'] = new_data['click_time'].dt.day\n",
    "        new_data['clk_hour'] = new_data['click_time'].dt.hour\n",
    "        new_data['clk_month'] = new_data['click_time'].dt.month\n",
    "        new_data['clk_dayofweek'] = new_data['click_time'].dt.dayofweek\n",
    "\n",
    "        new_data = new_data.drop(['click_time'], axis=1)\n",
    "\n",
    "        # number of clicks by different vars\n",
    "        data_lst = list(set(new_data.columns)-{target_var})\n",
    "        var_combo = list_combinations([], data_lst, [])\n",
    "        var_combo = [x for x in var_combo if len(x)<len(data_lst)]\n",
    "        var_names = []\n",
    "        \n",
    "        for i in range(len(var_combo)):\n",
    "            var_c = var_combo[i]\n",
    "\n",
    "            if len(var_c)>1:\n",
    "                var_n = 'clk_by_' + '_'.join(var_c)\n",
    "            else:\n",
    "                var_n = 'clk_by_' + var_c[0]\n",
    "                \n",
    "            var_names.append(var_n)\n",
    "\n",
    "            var_groupby = new_data.groupby(var_c).size().reset_index(name=var_n)\n",
    "            new_data = new_data.merge(var_groupby, on=var_c, how='left')\n",
    "    \n",
    "        return new_data, var_names\n",
    "\n",
    "    \n",
    "\n",
    "def denseDummies(df, cat_cols, cut_threshold=0.99, na_to_miss=True):\n",
    "    # To create some dummies for categorical variables\n",
    "    # By default, if there are more than 99% 1s or 0s, then drop the dummy.\n",
    "    \n",
    "    df_cat = df[cat_cols].astype('str')\n",
    "    df_cat = df_cat.replace(r'\\s+', np.nan, regex=True).replace('', np.nan)\n",
    "    \n",
    "    if na_to_miss:\n",
    "        df_cat = df_cat.fillna('miss_cat')\n",
    "    \n",
    "    df_dummies = pd.get_dummies(df_cat)  # generate dummies\n",
    "    df_dummies = remove_flat_columns(df_dummies, cut_threshold) # filter out sparse dummies\n",
    "    \n",
    "    df_num = df.drop(cat_cols, axis=1)\n",
    "    df_out = pd.concat([df_num, df_dummies], axis=1)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "def addMissingFlag(df, mynum, cutoff=0.03):\n",
    "    # For numeric columns, if missing% > 3%, create a flag variable for it.\n",
    "    nrow = df.shape[0]\n",
    "    df_miss_pct = df[mynum].isnull().sum()/nrow\n",
    "    df_to_flag = df_miss_pct.index[df_miss_pct > cutoff].tolist()\n",
    "    \n",
    "    # Add to output data frame\n",
    "    for f in df_to_flag:\n",
    "        var_name = 'missing_' + f\n",
    "        df[var_name] = df[f].isnull().astype('int')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def imputationDict(df, mynum=False, mycat=False):\n",
    "    # Prepare the imputation dictionary for a given data set\n",
    "    # --> get median for numeric columns\n",
    "    # --> get mode for categorical columns\n",
    "    # df = df.fillna(value=impute_dict)\n",
    "    \n",
    "    impute_dict = {}\n",
    "    \n",
    "    if mynum:\n",
    "        dict_num = dict(df[mynum].mean().round(2))\n",
    "        impute_dict = {**impute_dict, **dict_num}\n",
    "        \n",
    "    # get mode for categorical columns \n",
    "    if mycat:\n",
    "        dict_cat = df[mycat].mode().iloc[[0]].to_dict(orient='records')[0]\n",
    "        impute_dict = {**impute_dict, **dict_cat}\n",
    "    \n",
    "    return impute_dict\n",
    "\n",
    "\n",
    "\n",
    "def woe_monotonic(df, mynum):\n",
    "    # PyWoE\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def createBins(df, mynum):\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def highCorrelations(df, num_cols, target_variable, cutoff=0.95, verbose=False):\n",
    "    # Remove variables with high pairwise correlations \n",
    "    # and keep columns with highest correlation to dependent variable\n",
    "    # --> use the function after converting all cat to num\n",
    "    \n",
    "    x_num = list[set(num_cols).intersection(set(df.select_dtypes(exclude=['object']).columns.values))]\n",
    "    df_cor = df[x_num].corr() \n",
    "    item_remove = df_cor.columns[df_cor.isna().any()].tolist() # check missing\n",
    "    df_cor = df_cor.drop(columns=item_remove, index=item_remove)\n",
    "    \n",
    "    # Remove the lower triangle, including diagonals as this is symmetric\n",
    "    df_cor = df_cor.where(np.triu(np.ones(df_cor.shape)).astype(np.bool))\n",
    "    if verbose:\n",
    "        print('Completed calculation of all independent variable correlations.')\n",
    "        \n",
    "    # Grab the rows that are above the cutoff\n",
    "    df_cut_cor = df_cor[df_cor>cutoff][df_cor<1].dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "    row_names = list(df_cut_cor.index)\n",
    "    combs_above_cutoff = []\n",
    "    for i, j in enumerate(df_cut_cor):\n",
    "        combs_above_cutoff.append([row_names[i], j])\n",
    "    if verbose:\n",
    "        print('Completed applying cutoff.')\n",
    "    \n",
    "    # Absolute correlation with dependent variable for all variables in combs\n",
    "    combs_vars = list(set(sum(combs_above_cutoff, [])))\n",
    "    dep_var_corr = [df[cv].corr(df[target_variable]) for cv in combs_vars]\n",
    "    dep_var_corr_dict = dict(zip(combs_vars, dep_var_corr))\n",
    "    if verbose:\n",
    "        print('Completed calculation of all correlations.')\n",
    "    \n",
    "    # Pick the var have higher dep_var_corr in combs\n",
    "    var_to_keep = []\n",
    "    var_to_drop = []\n",
    "    for cv in combs_above_cutoff:\n",
    "        cv.sort(key=dep_var_corr_dict.get, reverse=True)\n",
    "        var_to_keep.append(cv[0])\n",
    "        var_to_drop.append(cv[1])\n",
    "    \n",
    "    var_to_keep = list(set(var_to_keep))\n",
    "    var_to_drop = list(set(var_to_drop))\n",
    "    \n",
    "    return var_to_keep, var_to_drop\n",
    "\n",
    "\n",
    "\n",
    "def cleanColumnNames(df):\n",
    "    # Replace all non-alphanumeric characters with underscore\n",
    "    df.columns = df.columns.str.replace('[^0-9a-zA-Z]+','_')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the number of clicks by different combination of cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lli2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/lli2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/lli2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/lli2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "test = df_train[1:1000]\n",
    "target_var = 'is_attributed'\n",
    "\n",
    "test, test_combo_num = clicks_creation(test, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 520)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>clk_date</th>\n",
       "      <th>clk_hour</th>\n",
       "      <th>clk_month</th>\n",
       "      <th>clk_dayofweek</th>\n",
       "      <th>...</th>\n",
       "      <th>clk_by_channel_ip</th>\n",
       "      <th>clk_by_channel_ip_os</th>\n",
       "      <th>clk_by_channel_os</th>\n",
       "      <th>clk_by_clk_month</th>\n",
       "      <th>clk_by_clk_month_ip</th>\n",
       "      <th>clk_by_clk_month_ip_os</th>\n",
       "      <th>clk_by_clk_month_os</th>\n",
       "      <th>clk_by_ip</th>\n",
       "      <th>clk_by_ip_os</th>\n",
       "      <th>clk_by_os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>281</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  is_attributed  clk_date  clk_hour  \\\n",
       "0   17357    3       1  19      379              0         6        14   \n",
       "1   35810    3       1  13      379              0         6        14   \n",
       "2   45745   14       1  13      478              0         6        14   \n",
       "3  161007    3       1  13      379              0         6        14   \n",
       "4   18787    3       1  16      379              0         6        14   \n",
       "\n",
       "   clk_month  clk_dayofweek    ...      clk_by_channel_ip  \\\n",
       "0         11              0    ...                      2   \n",
       "1         11              0    ...                      1   \n",
       "2         11              0    ...                      1   \n",
       "3         11              0    ...                      1   \n",
       "4         11              0    ...                      2   \n",
       "\n",
       "   clk_by_channel_ip_os  clk_by_channel_os  clk_by_clk_month  \\\n",
       "0                     1                132               999   \n",
       "1                     1                149               999   \n",
       "2                     1                  4               999   \n",
       "3                     1                149               999   \n",
       "4                     1                  7               999   \n",
       "\n",
       "   clk_by_clk_month_ip  clk_by_clk_month_ip_os  clk_by_clk_month_os  \\\n",
       "0                    2                       1                  281   \n",
       "1                    1                       1                  281   \n",
       "2                    3                       3                  281   \n",
       "3                    1                       1                  281   \n",
       "4                    2                       1                   11   \n",
       "\n",
       "   clk_by_ip  clk_by_ip_os  clk_by_os  \n",
       "0          2             1        281  \n",
       "1          1             1        281  \n",
       "2          3             3        281  \n",
       "3          1             1        281  \n",
       "4          2             1         11  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical variables to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['device',\n",
       " 'clk_hour',\n",
       " 'clk_date',\n",
       " 'app',\n",
       " 'clk_dayofweek',\n",
       " 'clk_month',\n",
       " 'channel',\n",
       " 'ip',\n",
       " 'os']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_var = ['is_attributed' ]\n",
    "mycat = list(set(test.columns)-set(target_var + test_combo_num))\n",
    "mycat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 520)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(999, 559)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test = denseDummies(test, mycat)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_cat, df_dummies, df_num, df_out\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics:\n",
    "* Correlation among variables\n",
    "\n",
    "Unsupervised Methods:\n",
    "* PCA: converts our original variables to a new set of variables, which are a linear combination of the original set of variables. \n",
    "* SVD\n",
    "* LDA\n",
    "\n",
    "Supervised Methods:\n",
    "* Boostrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, withen=True)\n",
    "x_pca = pca.fit(df_x).transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100)\n",
    "x_svd = svd.fit(df_x).transform(df_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Train and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create binary training and validation files for XGBoost\n",
    "x1, y1 = X[:train_size], y.iloc[:train_size]\n",
    "dm1 = xgb.DMatrix(x1, y1, feature_names=feature_names)\n",
    "dm1.save_binary('train.bin')\n",
    "del dm1, x1, y1\n",
    "gc.collect()\n",
    "\n",
    "x2, y2 = X[train_size:], y.iloc[train_size:]\n",
    "dm2 = xgb.DMatrix(x2, y2, feature_names=feature_names)\n",
    "dm2.save_binary('validate.bin')\n",
    "del dm2, x2, y2\n",
    "del X, y, train_sparse\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgreg = LogisticRegression()\n",
    "lgreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling with XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'eta': 0.3,\n",
    "    'tree_method': \"hist\",\n",
    "    'grow_policy': \"lossguide\",\n",
    "    'max_leaves': 1000,  \n",
    "    'max_depth': 0, \n",
    "    'subsample': 0.9, \n",
    "    'alpha':1,\n",
    "    'objective': 'binary:logistic', \n",
    "    'scale_pos_weight':100,\n",
    "    'eval_metric': 'auc', \n",
    "    'nthread':4,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
